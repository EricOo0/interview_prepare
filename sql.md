# SQL&&Redis  

<details>
<summary>结构</summary>

* 结构：  

>应用层：连接处理--连接池，用户鉴权，安全处理
MySQL服务层：提供数据管理，sql解释，优化等
存储引擎层：实际存储数据的系统

</details>

<details>

<summary>Sql搜索可以考虑的数据结构</summary>

* Sql搜索可以考虑的数据结构

>目标：高效，快速  
哈希表：O（1）的处理速度，单点搜索快但是不适合范围查找，排序  
二叉树：O（logn）的时间复杂度，天然的排序特性，但容易不平衡  
AVL：严格平衡但是旋转耗时且IO消耗较大，如果深的话（一次查找一个值，进行一次IO）  
B树：有序数组+平衡多叉树；  
每个子节点可以存放多个值，树深度降低，适合查找  
B+树：有序数组链表+平衡多叉树  
每个子节点不存放值，只存放索引（地址），在叶子节点存放所有的数据，且用链表链接所有叶子节点（更适合范围查找，减少磁盘IO次数），每次查询需要的次数是一样的  

</details>

<details>
<summary>Redo_log 和 undo_log</summary>

1、概念：

​	undo log是逻辑日志，记录是操作记录日志，redo log是物理日志，记录的是新数据；undo log不是redo log的逆向过程

2、用处：

​	undo log是为了保证事务原子性而设计的，redo log是为了保证事务持久性设置的。

​	undo log在InnoDB中用来实现多版本控制mvcc，执行rollback操作时，undo log可以作为事务回滚的快照读参考。

​	redo log是备份的最新数据位置，系统冗机时，只要重启mysql服务，就可以将未持久保存的数据持久到磁盘

3、redo log：

* 只记录该存储引擎中表的修改，是在物理格式上的日志，它记录的是数据库中每个页的修改。

* MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。

<img src="image/image-20211008112658017.png" alt="image-20211008112658017" style="zoom:40%;" />

</details>

<details>

  <summary>水平分表 和 垂直分表</summary>
  关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。

  * 垂直分库：

    垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。例如：

    <img src="image/image-20211015112004097.png" alt="image-20211015112004097" style="zoom:40%;" />

* 垂直分表：

  垂直分表是基于数据库中的"列"进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中,通过拆分字段，也可以避免跨页问题。ps: [MySQL](https://jhrtech.cn/sql/135779.html)底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。

* 水平切分-库内分表：

  根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小。

  <img src="image/image-20211015112447465.png" alt="image-20211015112447465" style="zoom:40%;" />

  

  

</details>



* 四大特性：  

>ACID:原子性atomic，一致性consistency，隔离性：isolation，持久性duration  
原子性：利用undo_log；失败回滚  
持久性：redo_log和刷入磁盘持久化  
隔离性：加锁和mvcc  

* 事务实现：
>事务的实现依靠redo log：数据库的操作先写到缓存中和redo log buffer里，commit后同步到数据库中，实现持久化

* 三大范式:  

>第一范式：字段不可再拆分成子字段  
第二范式：各字段都和主键有联系  
第三范式：各字段只和主键有全部联系（只依赖于主键）  
* 五大约束：  

>唯一约束：unique  
主键约束 primary  
外键约束:foreign  
默认约束：default  
非空约束：notnull    
* 索引类型  

>1.普通索引  
2.唯一索引 ：索引列的值必须唯一 ，允许null！  
3.主键索引 ：一个表只能有一个主键，不允许有空值  
4.组合索引  
5.全文索引  

* 聚蔟索引和非聚蔟索引  
> 聚蔟索引：将数据存储与索引放到了一块，找到索引也就找到了数据，一般主键就是聚蔟索引，叶子节点存放了数据；只有一个  
非聚蔟索引：又叫二级索引，辅助索引，叶子节点存储的是主键的值  
聚蔟索引是innodb的特性，mysiam没有，如果需要使用聚蔟索引，设置主键即可，如果没有主键，会用一个唯一且非空的列为主键，也没有的话innodb会创建一个虚拟主键   

* 数据库回表  
通过辅助索引(非聚蔟索引)，找到主键，在查询表中数据的过程叫回表，如果只需要辅助索引的键值，则不需要回表--这种是覆盖索引  

* 不走索引的情况

>对索引列使用函数  
>or的列有的没有建立索引--可以用union查询
>索引列是string却用int去查询，(int 可以用 char查询)
>联合索引不满足最左匹配 a/ab/abc abc只走a
>
>* 数据库索引：加快检索表中数据的方法  
>* Mysql索引：  

>索引可以提高检索速度但会降低更新速度，需要更新索引文件  
* Mysql主要包含四种隔离状态  

>读未提交Read Uncommitted：脏读-在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。  
读取提交内容Read committed：一个事务只能看见已经提交事务所做的改变  
可重复读 ：幻读，提交前读取的数据不变  
串行化  

* 数据库事务隔离：  

>查询隔离等级：SHOW VARIABLES LIKE '%isolation'; or SELECT @@session.transaction_isolation;
>
>修改隔离等级：
>
>```sql
>SET [GLOBAL | SESSION] TRANSACTION ISOLATION LEVEL
>  {
>       REPEATABLE READ   --可重复读。幻读
>     | READ COMMITTED   --已提交读 不可重复读
>     | READ UNCOMMITTED --未提交度 脏读
>     | SERIALIZABLE
>   }
>```
>
>同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。  
>
>*  mysql有哪几种锁
>myisam支持表级锁  
>innodb支持行锁  
>读锁写锁（或者叫排他锁共享锁）
>间隙锁


* MVCC理解
>1、什么是MVCC？
    多版本并发控制
    https://juejin.cn/post/6871046354018238472
    https://juejin.cn/post/6844903986143690765
2、实现方式？
事务隔离实现两种方式一种是加读写锁(串行化)，另一种就是MVCC.
MVCC主要是通过在每一行记录中增加三个字段，与 undo log 中相关记录配合使用，同时加上可见性算法，使得各个事务可以在不加锁的情况下能够同时地读取到某行记录上的准确值（这个值对不同的事务而言可能是不同的）。使用 MVCC，在不加锁的情况下也能读取到准确的数据，大大提高了并发效率。
>>1、对于数据库中的每条数据，添加三个字段（trx_id;roll_ptr;row_id）
2、当事务对数据进行更新时，会将操作写入undo log，并且更新数据的trx_id和roll_ptr
3、当事务进行查询的时候，通过roll_ptr去找到当前事务能读到的最近历史版本的数据(比较trx_id和read_view)
关键:
roll_ptr--**版本链**
**undo日志**
**read_view**
>>>read_view-一致性视图
用于可见性判断，事务在创建的时候会生成一个快照，由下列4个部分组成：
creator_trx_id:当前事务id
m_ids:所有事务的事务id
min_trx_id:m_ids里最小的事务id值
max_trx_id:最大事务id
如果是已提交读，那么每一个语句执行前都会重新算出一个新的视图，如果是可重复读，则是执行事务时创建
四种隔离级别，只有「读提交」和「可重复度」两个隔离级别能够使用 MVCC，因此也只有这两个隔离级别会创建一致性视图（read-view）
可重复读会带来幻读的问题，可通过间隙锁解决 select ... for update
* 权限设置：  

>通过用户名密码登录到账户  
Grand 权限（update，drop等）on 表 to 用户  
Revoke 撤销权限  
* 存储引擎：负责数据库中的数据的存储和查提取。使用不同的技术将数据存储在

>文件或内存中(不同的表结构)；show engine看存储引擎  
Myisam：不支持事务，（基于hash）但是插入数据快，适合在插入或选择密集（读或写的多单一业务）数据库，对硬件要求低，表锁：不会发生锁冲突  
Innodb：支持事务，支持事务提交和回滚，加入外键约束，适合多重并发（更新密集）的数据库，行锁：容易死锁  
Memory：运行在内存上，速度快但容易丢失，不支持事务  

![image text](https://github.com/EricOo0/my_repo/blob/88853547c0b5a73f8ecd1492103a8e32f2dbd88c/Image/innodb.jpg)

* sql分区：  

>MySQL在创建表的时候可以通过使用PARTITION BY子句定义每个分区存放的数据。在执行查询的时候，优化器根据分区定义过滤那些没有我们需要的数据的分区，这样查询就可以无需扫描所有分区，只需要查找包含需要数据的分区即可。  
create TABLE tblname (upload_date string,FTarget string) PARTITION BY RANGE (upload_date) (partition p_20210615 values less than (20210615) )  
常用分区类型：range；list
查看某个分区信息：  
show create table partition_test；查看创建表的语句  
show table status；看表是不是分区表  
information_schema.PARTITIONS 存储分区信息，可以去这张表查    
SELECT * FROM tr p2;查看这个分区的信息    
alter table partition_test add partition  (partition p_20210616 values less than (20210616));增加分区  


* binlog有几种格式
>1、Statement：每一条会修改数据的sql都会记录在binlog中。  
2、不记录sql语句上下文相关信息，仅保存哪条记录被修改  
3、Mixedlevel: 是以上两种level的混合使用  

* 从binlog恢复数据  
mysqlbinlog命令  
mysqlbinlog --start-position=154  --stop-position=513  bin-log.000001 > /path/bak.sql;  
mysql -uroot -p < /path/bak.sql  


* Mysql主从一致：  
>从库复制主库的binlog日志，执行日志命令来复制（两个线程）  
>1、主从同步作用：  
>  从服务器起备份作用；  
>  主服务器挂掉的时候，从服务器可以起作用；  
>  可以用来做读写分离  
>2、分工-流程：  
>  主数据服务器：主要用来从业务服务写入数据或者修改更新数据。  
>  从数据服务器：主要用来读取业务所需要的数据  
>  二进制日志：用来存储写入以及更新的数据信息  
>  中继日志：承接主服务器数据信息，转存在从服务器上  
>  I/O线程：监听主服务器是否发生数据更改的行为  
>  SQL线程：将主服务器数据更改的数据从中继日志文件中读取数据写入到从数据服务器中
>当主数据服务器master进行写入数据或者更新数据操作的时候，数据更改会记录在二进制日志（binary log file）中，主服务器master与从服务器slave进行通讯的是I/O线程，它将修改的数据异步复制写入到slave服务器的中继日志（relay log file）中,从服务器slave与中继日志之间通信使用SQL线程，SQL线程可以异步从中继日志中读取数据后再写入到自己的数据库中，就完成了数据的主从同步功能。  
>
>3、复制方式
>
>​	默认为异步复制：主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。
>
>​	全同步复制：当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。
>
>半同步复制：介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全完成并且提交的反馈，如此，节省了很多时间。
>
>4、主从同步在物理上必然有延迟的现象，1⃣️如果追求数据一致性，可以使用全同步复制或半同步复制；2⃣️利用数据库中间件，所有的读写都走数据库中间件，通常情况下，写请求路由到主库，读请求路由到从库。当有写操作发生时的一个时间窗口内，把读操作请求到主库，后面在放到从库。3⃣️利用缓存，读操作时看看缓存是否命中，命中就去主库读，复制从库读，缓存有超时时间，和同步到从库时间接近。

![master-slave](https://github.com/EricOo0/my_repo/blob/master/Image/master-slave.png)

* Mysql回滚  
>使用begin开始一个事务，在commit之前可以回滚rollback  
* 连接池：
>数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个  
一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的性能低下。  
数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并讲这些连接组成一个连接池(简单说：在一个“池”里放了好多半成品的数据库联接对象)  
1\程序初始化时创建连接池    
2\使用时向连接池申请可用连接  
3\使用完毕，将连接返还给连接池  
4\程序退出时，断开连接，并释放资源  
* 存储过程：  
>预先通过编译和存储在数据库的一段sql命令集合  
* 绑定变量
>减少解析次数，提高效率  


* redis:  
  
>非关系型数据库，是单线程的结构型数据存储(key-value)，用C实现的  
模型：IO多路复用+单线程  
用SET和GET设置和获取数据  
支持五种数据结构：  
key:string字符串  value: string list hashmap set zset（有序集合）等   
string --sds，自动记录字符串长度
list--双端链表实现  lpush rpush lrange  
哈希表--数组+链表实现；解决哈希冲突：链表发，新节点加到头--rehash；hset，hget；key和value交替填入  
set--集合sadd添加spop弹出；  
zset--有序列表：用跳表实现  
持久化方式：  
    RDB和AOF  
    RDB简而言之，就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上；   
    AOF 方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，  
支持主从复制，读写分离  
* 内存管理机制上：  
>Redis 数据全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU（最少使用） 算法删除数据  

* 位图和布隆过滤器
>面对海量数据的去重和过滤问题，系统内存不够，可以考虑使用位图和布隆过滤器解决：  
>1、布隆过滤器：可用来检查数据可能在集合中或者一定不在集合中  
>使用一个长度为m的向量或位列表，初始值全为0  
>为了将数据插入列表，提供了k个哈希散列函数(输出为单个索引值)，每个数据通过哈希函数得到k个索引，将k个索引位置1  
>
>2、布隆过滤器误判率：
>
>假设布隆过滤器大小为m比特，存储了n个元素，使用k次散列函数来计算元素的存储位置。
>
>添加1个元素，则任一比特为1的概率为：1/m，任一比特为0的概率：1-1/m；
>
>添加1个元素，执行k次散列之后，则任一比特为0的概率：(1-1/m)^k，任一比特为1的概率：1-(1-1/m)^k；
>
>如果添加n个元素，那么任一比特为0的概率：(1-1/m)^kn，任一比特为1的概率：1-(1-1/m)^kn；
>
>如果将1个新的元素，添加到已存在n个元素的布隆过滤器中，则任一比特已经为1的概率与上面相同，概率为：1-(1-1/m)^kn。因此，k个比特都为1的概率为：(1-(1-1/m)^kn)^k，此即为新插入元素的误识别率。
>

![bloom](https://github.com/EricOo0/zhifengwei.blog/blob/main/Image/boolen.png)  

>判断元素是否存在集合中，k个索引位都为1--可能存在误判
应用：数据去重；缓解缓存穿透  
3、位图：每一个bit代表一个数据，用一个bit数据来记录数据可以减少内存使用  
如果用一个int数组存储：int  a[N]--可以记录N*4*8个数据
数据记录：num/32=第几个字节  num%32=该字节的第几位
数据判断：判断对应的字节和位是否为1
问题：bitmap的大小和存储的最大数据有关，如果数据很大但量很小会浪费空间